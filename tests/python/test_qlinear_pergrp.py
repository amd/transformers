#
# Copyright Â© 2023 Advanced Micro Devices, Inc. All rights reserved.
#

import gc
import logging
import os
import time

import numpy as np
import psutil
import pytest
import qlinear
import RyzenAI
import torch

torch.random.manual_seed(123)
np.random.seed(123)

opt_1p3b = [
    {"shape": ((1, 2048), (2048, 2048)), "group_size": 128, "target_err_percent": 1.0},
    {"shape": ((1, 2048), (8192, 2048)), "group_size": 128, "target_err_percent": 1.0},
    {"shape": ((1, 8192), (2048, 8192)), "group_size": 128, "target_err_percent": 1.0},
    {
        "shape": ((1, 2048), (50272, 2048)),
        "group_size": 128,
        "target_err_percent": 2.21,
    },
    {"shape": ((1, 2048), (2048, 2048)), "group_size": 64, "target_err_percent": 1.0},
    {"shape": ((1, 2048), (8192, 2048)), "group_size": 64, "target_err_percent": 1.51},
    {"shape": ((1, 8192), (2048, 8192)), "group_size": 64, "target_err_percent": 1.0},
    {"shape": ((1, 2048), (50272, 2048)), "group_size": 64, "target_err_percent": 2.5},
    {"shape": ((1, 2048), (2048, 2048)), "group_size": 32, "target_err_percent": 1.0},
    {"shape": ((1, 2048), (8192, 2048)), "group_size": 32, "target_err_percent": 3.907},
    {"shape": ((1, 8192), (2048, 8192)), "group_size": 32, "target_err_percent": 2.28},
    {"shape": ((1, 2048), (50272, 2048)), "group_size": 32, "target_err_percent": 3.58},
    {
        "shape": ((128, 2048), (2048, 2048)),
        "group_size": 128,
        "target_err_percent": 6.7,
    },
    {
        "shape": ((128, 2048), (8192, 2048)),
        "group_size": 128,
        "target_err_percent": 53.16,
    },
    {
        "shape": ((128, 8192), (2048, 8192)),
        "group_size": 128,
        "target_err_percent": 84.38,
    },
    {
        "shape": ((128, 2048), (50272, 2048)),
        "group_size": 128,
        "target_err_percent": 53.13,
    },
    {
        "shape": ((128, 2048), (2048, 2048)),
        "group_size": 64,
        "target_err_percent": 48.44,
    },
    {
        "shape": ((128, 2048), (8192, 2048)),
        "group_size": 64,
        "target_err_percent": 42.969,
    },
    {
        "shape": ((128, 8192), (2048, 8192)),
        "group_size": 64,
        "target_err_percent": 39.84,
    },
    {
        "shape": ((128, 2048), (50272, 2048)),
        "group_size": 64,
        "target_err_percent": 47.66,
    },
    {
        "shape": ((128, 2048), (2048, 2048)),
        "group_size": 32,
        "target_err_percent": 28.91,
    },
    {
        "shape": ((128, 2048), (8192, 2048)),
        "group_size": 32,
        "target_err_percent": 42.19,
    },
    {
        "shape": ((128, 8192), (2048, 8192)),
        "group_size": 32,
        "target_err_percent": 11.17,
    },
    {
        "shape": ((128, 2048), (50272, 2048)),
        "group_size": 32,
        "target_err_percent": 48.44,
    },
]

llama2_7b = [
    {"shape": ((1, 4096), (4096, 4096)), "group_size": 128, "target_err_percent": 1.0},
    {"shape": ((1, 4096), (11008, 4096)), "group_size": 128, "target_err_percent": 1.0},
    {
        "shape": ((1, 11008), (4096, 11008)),
        "group_size": 128,
        "target_err_percent": 1.0,
    },
    {"shape": ((1, 4096), (32000, 4096)), "group_size": 128, "target_err_percent": 1.1},
    {"shape": ((1, 4096), (32000, 4096)), "group_size": 32, "target_err_percent": 3.9},
    {
        "shape": ((128, 4096), (4096, 4096)),
        "group_size": 128,
        "target_err_percent": 7.6,
    },
    {
        "shape": ((128, 4096), (11008, 4096)),
        "group_size": 128,
        "target_err_percent": 7.6,
    },
    {
        "shape": ((128, 11008), (4096, 11008)),
        "group_size": 128,
        "target_err_percent": 4.4,
    },
    {
        "shape": ((128, 4096), (32000, 4096)),
        "group_size": 128,
        "target_err_percent": 38.9,
    },
    {
        "shape": ((128, 4096), (32000, 4096)),
        "group_size": 32,
        "target_err_percent": 49.3,
    },
]

qwen1p5_7b = [
    {
        "shape": ((1, 4096), (151936, 4096)),
        "group_size": 128,
        "target_err_percent": 7.9,
    },
    {
        "shape": ((128, 4096), (151936, 4096)),
        "group_size": 128,
        "target_err_percent": 55.6,
    },
    {
        "shape": ((1, 4096), (151936, 4096)),
        "group_size": 32,
        "target_err_percent": 28.2,
    },
    {
        "shape": ((128, 4096), (151936, 4096)),
        "group_size": 32,
        "target_err_percent": 50.0,
    },
]

starcoder = [
    {"shape": ((1, 6144), (6400, 6144)), "group_size": 128, "target_err_percent": 1.0},
    {"shape": ((1, 6400), (6144, 6400)), "group_size": 128, "target_err_percent": 1.0},
    {"shape": ((1, 6144), (24576, 6144)), "group_size": 128, "target_err_percent": 2.4},
    {
        "shape": ((1, 24576), (6144, 24576)),
        "group_size": 128,
        "target_err_percent": 1.0,
    },
    {"shape": ((1, 6144), (49152, 6144)), "group_size": 128, "target_err_percent": 2.4},
    {"shape": ((1, 6144), (49152, 6144)), "group_size": 32, "target_err_percent": 3.0},
    {
        "shape": ((128, 6144), (6400, 6144)),
        "group_size": 128,
        "target_err_percent": 9.4,
    },
    {
        "shape": ((128, 6400), (6144, 6400)),
        "group_size": 128,
        "target_err_percent": 4.7,
    },
    {
        "shape": ((128, 6144), (24576, 6144)),
        "group_size": 128,
        "target_err_percent": 41.5,
    },
    {
        "shape": ((128, 24576), (6144, 24576)),
        "group_size": 128,
        "target_err_percent": 71.9,
    },
    {
        "shape": ((128, 6144), (49152, 6144)),
        "group_size": 128,
        "target_err_percent": 41.5,
    },
    {
        "shape": ((128, 6144), (49152, 6144)),
        "group_size": 32,
        "target_err_percent": 52.35,
    },
]

codellama2_7b = [
    {"shape": ((1, 4096), (32016, 4096)), "group_size": 128, "target_err_percent": 1.1},
    {
        "shape": ((128, 4096), (32016, 4096)),
        "group_size": 128,
        "target_err_percent": 38.3,
    },
    {"shape": ((1, 4096), (32016, 4096)), "group_size": 32, "target_err_percent": 3.9},
    {
        "shape": ((128, 4096), (32016, 4096)),
        "group_size": 32,
        "target_err_percent": 49.3,
    },
]

chatglm = [
    {"shape": ((1, 4096), (16384, 4096)), "group_size": 128, "target_err_percent": 1.1},
    {
        "shape": ((1, 16384), (4096, 16384)),
        "group_size": 128,
        "target_err_percent": 1.1,
    },
    {"shape": ((1, 4096), (12288, 4096)), "group_size": 128, "target_err_percent": 1.1},
    {
        "shape": ((1, 4096), (130528, 4096)),
        "group_size": 128,
        "target_err_percent": 7.9,
    },
    {"shape": ((1, 4096), (16384, 4096)), "group_size": 32, "target_err_percent": 3.9},
    {"shape": ((1, 16384), (4096, 16384)), "group_size": 32, "target_err_percent": 1.1},
    {"shape": ((1, 4096), (12288, 4096)), "group_size": 32, "target_err_percent": 1.1},
    {
        "shape": ((1, 4096), (130528, 4096)),
        "group_size": 32,
        "target_err_percent": 28.2,
    },
    {
        "shape": ((128, 4096), (16384, 4096)),
        "group_size": 128,
        "target_err_percent": 7.6,
    },
    {
        "shape": ((128, 16384), (4096, 16384)),
        "group_size": 128,
        "target_err_percent": 4.6,
    },
    {
        "shape": ((128, 4096), (12288, 4096)),
        "group_size": 128,
        "target_err_percent": 7.6,
    },
    {
        "shape": ((128, 4096), (130528, 4096)),
        "group_size": 128,
        "target_err_percent": 55.6,
    },
    {
        "shape": ((128, 4096), (16384, 4096)),
        "group_size": 32,
        "target_err_percent": 49.3,
    },
    {
        "shape": ((128, 16384), (4096, 16384)),
        "group_size": 32,
        "target_err_percent": 14.9,
    },
    {
        "shape": ((128, 4096), (12288, 4096)),
        "group_size": 32,
        "target_err_percent": 49.3,
    },
    {
        "shape": ((128, 4096), (130528, 4096)),
        "group_size": 32,
        "target_err_percent": 49.3,
    },
]

chatglm3 = [
    {"shape": ((1, 4096), (4608, 4096)), "group_size": 128, "target_err_percent": 1.1},
    {"shape": ((1, 4096), (4096, 4096)), "group_size": 128, "target_err_percent": 1.1},
    {"shape": ((1, 4096), (27392, 4096)), "group_size": 128, "target_err_percent": 1.1},
    {
        "shape": ((1, 13696), (4096, 13696)),
        "group_size": 128,
        "target_err_percent": 2.4,
    },
    {"shape": ((1, 4096), (65024, 4096)), "group_size": 128, "target_err_percent": 1.1},
    {"shape": ((1, 4096), (4608, 4096)), "group_size": 32, "target_err_percent": 1.1},
    {"shape": ((1, 4096), (4096, 4096)), "group_size": 32, "target_err_percent": 1.1},
    {"shape": ((1, 4096), (27392, 4096)), "group_size": 32, "target_err_percent": 3.9},
    {"shape": ((1, 13696), (4096, 13696)), "group_size": 32, "target_err_percent": 1.1},
    {"shape": ((1, 4096), (65024, 4096)), "group_size": 32, "target_err_percent": 28.2},
    {
        "shape": ((128, 4096), (4608, 4096)),
        "group_size": 128,
        "target_err_percent": 7.6,
    },
    {
        "shape": ((128, 4096), (4096, 4096)),
        "group_size": 128,
        "target_err_percent": 7.6,
    },
    {
        "shape": ((128, 4096), (27392, 4096)),
        "group_size": 128,
        "target_err_percent": 38.3,
    },
    {
        "shape": ((128, 13696), (4096, 13696)),
        "group_size": 128,
        "target_err_percent": 13.8,
    },
    {
        "shape": ((128, 4096), (65024, 4096)),
        "group_size": 128,
        "target_err_percent": 38.3,
    },
    {
        "shape": ((128, 4096), (4608, 4096)),
        "group_size": 32,
        "target_err_percent": 49.3,
    },
    {
        "shape": ((128, 4096), (4096, 4096)),
        "group_size": 32,
        "target_err_percent": 49.3,
    },
    {
        "shape": ((128, 4096), (27392, 4096)),
        "group_size": 32,
        "target_err_percent": 49.3,
    },
    {
        "shape": ((128, 13696), (4096, 13696)),
        "group_size": 32,
        "target_err_percent": 62.5,
    },
    {
        "shape": ((128, 4096), (65024, 4096)),
        "group_size": 32,
        "target_err_percent": 49.3,
    },
]

gemma7b = [
    {"shape": ((1, 3072), (4096, 3072)), "group_size": 128, "target_err_percent": 1.1},
    {"shape": ((1, 4096), (3072, 4096)), "group_size": 128, "target_err_percent": 1.1},
    {"shape": ((1, 3072), (24576, 3072)), "group_size": 128, "target_err_percent": 2.0},
    {
        "shape": ((1, 24576), (3072, 24576)),
        "group_size": 128,
        "target_err_percent": 1.1,
    },
    {
        "shape": ((1, 3072), (256000, 3072)),
        "group_size": 128,
        "target_err_percent": 12.5,
    },
    {"shape": ((1, 3072), (4096, 3072)), "group_size": 32, "target_err_percent": 1.1},
    {"shape": ((1, 4096), (3072, 4096)), "group_size": 32, "target_err_percent": 1.1},
    {"shape": ((1, 3072), (24576, 3072)), "group_size": 32, "target_err_percent": 1.0},
    {"shape": ((1, 24576), (3072, 24576)), "group_size": 32, "target_err_percent": 1.1},
    {"shape": ((1, 3072), (256000, 3072)), "group_size": 32, "target_err_percent": 6.3},
    {
        "shape": ((128, 3072), (4096, 3072)),
        "group_size": 128,
        "target_err_percent": 4.0,
    },
    {
        "shape": ((128, 4096), (3072, 4096)),
        "group_size": 128,
        "target_err_percent": 5.8,
    },
    {
        "shape": ((128, 3072), (24576, 3072)),
        "group_size": 128,
        "target_err_percent": 45.4,
    },
    {
        "shape": ((128, 24576), (3072, 24576)),
        "group_size": 128,
        "target_err_percent": 18.8,
    },
    {
        "shape": ((128, 3072), (256000, 3072)),
        "group_size": 128,
        "target_err_percent": 45.4,
    },
    {"shape": ((128, 3072), (4096, 3072)), "group_size": 32, "target_err_percent": 6.3},
    {
        "shape": ((128, 4096), (3072, 4096)),
        "group_size": 32,
        "target_err_percent": 49.3,
    },
    {
        "shape": ((128, 3072), (24576, 3072)),
        "group_size": 32,
        "target_err_percent": 25.8,
    },
    {
        "shape": ((128, 24576), (3072, 24576)),
        "group_size": 32,
        "target_err_percent": 20.4,
    },
    {
        "shape": ((128, 3072), (256000, 3072)),
        "group_size": 32,
        "target_err_percent": 56.3,
    },
]


test_shapes = (
    opt_1p3b
    + llama2_7b
    + qwen1p5_7b
    + starcoder
    + codellama2_7b
    + chatglm
    + chatglm3
    + gemma7b
)


@pytest.mark.parametrize("xyshape", test_shapes)
def test_QLinear_pergrp(xyshape, w_bit):
    if os.getenv("MLADF"):
        pytest.skip("Test only relevant for non MLADF transaction binaries.")
    inp_shape, weight_shape = xyshape["shape"]
    grpsize = xyshape["group_size"]

    torch.random.manual_seed(123)
    np.random.seed(123)

    x_min, x_max = -42.0, 42.0
    x = np.random.uniform(low=x_min, high=x_max, size=inp_shape)
    x = torch.tensor(x).to(torch.bfloat16)

    y_min, y_max = -1.0, 1.0
    y = np.random.uniform(low=y_min, high=y_max, size=weight_shape).astype(np.float32)

    bias = torch.rand(y.shape[0], dtype=torch.float32)

    gemm_cpu = qlinear.QLinearPerGrp(
        in_features=inp_shape[1],
        out_features=weight_shape[0],
        bias=True,
        device="cpu",
        w_bit=w_bit,
        group_size=grpsize,
    )
    gemm_aie = qlinear.QLinearPerGrp(
        in_features=inp_shape[1],
        out_features=weight_shape[0],
        bias=True,
        device="cpu",
        w_bit=w_bit,
        group_size=grpsize,
    )

    gemm_cpu.weight = torch.from_numpy(y)
    gemm_cpu.bias = bias
    gemm_cpu.quantize_weights()
    gemm_cpu.device = "cpu"
    gemm_cpu.initialize_parameters()

    gemm_aie.weight = torch.from_numpy(y)
    gemm_aie.bias = bias
    gemm_aie.quantize_weights()
    gemm_aie.device = "aie"
    gemm_aie.initialize_parameters()

    res0 = gemm_cpu(x).to(torch.float64)
    res2 = gemm_aie(x).to(torch.float64)

    print(res0)
    print(res2)

    target_err_percent = xyshape["target_err_percent"]

    print((res0 - res2).abs().max())
    nz = torch.nonzero(res0, as_tuple=True)
    errpercent = ((res0[nz] - res2[nz]).abs() / res0[nz]).max() * 100.0
    if errpercent <= target_err_percent:
        print(f"***** PASS: res0 vs res2: {errpercent}")
        result3 = True
    else:
        print(f"***** FAIL: res0 vs res2: {errpercent}")
        result3 = False

    assert result3 == True


llama2_7b_mladf = [
    {
        "shape": ((1, 11008), (4096, 11008)),
        "group_size": 128,
        "target_max_error": 64.0,
        "target_mean_error": 12.1,
    },
    {
        "shape": ((1, 4096), (4096, 4096)),
        "group_size": 128,
        "target_max_error": 32.0,
        "target_mean_error": 6.8,
    },
    {
        "shape": ((1, 4096), (11008, 4096)),
        "group_size": 128,
        "target_max_error": 32.0,
        "target_mean_error": 6.8,
    },
    {
        "shape": ((1, 4096), (12288, 4096)),
        "group_size": 128,
        "target_max_error": 32.0,
        "target_mean_error": 6.8,
    },
    {
        "shape": ((1, 4096), (32768, 4096)),
        "group_size": 128,
        "target_max_error": 48.0,
        "target_mean_error": 6.9,
    },
    {
        "shape": ((128, 11008), (4096, 11008)),
        "group_size": 128,
        "target_max_error": 96.0,
        "target_mean_error": 11.9,
    },
    {
        "shape": ((128, 4096), (4096, 4096)),
        "group_size": 128,
        "target_max_error": 48.0,
        "target_mean_error": 6.8,
    },
    {
        "shape": ((128, 4096), (11008, 4096)),
        "group_size": 128,
        "target_max_error": 48.0,
        "target_mean_error": 6.8,
    },
    {
        "shape": ((128, 4096), (12288, 4096)),
        "group_size": 128,
        "target_max_error": 48.0,
        "target_mean_error": 6.8,
    },
    {
        "shape": ((128, 4096), (32768, 4096)),
        "group_size": 128,
        "target_max_error": 64.0,
        "target_mean_error": 6.9,
    },
    {
        "shape": ((256, 11008), (4096, 11008)),
        "group_size": 128,
        "target_max_error": 96.0,
        "target_mean_error": 11.9,
    },
    {
        "shape": ((256, 4096), (4096, 4096)),
        "group_size": 128,
        "target_max_error": 48.0,
        "target_mean_error": 6.8,
    },
    {
        "shape": ((256, 4096), (11008, 4096)),
        "group_size": 128,
        "target_max_error": 48.0,
        "target_mean_error": 6.8,
    },
    {
        "shape": ((256, 4096), (12288, 4096)),
        "group_size": 128,
        "target_max_error": 48.0,
        "target_mean_error": 6.8,
    },
    {
        "shape": ((256, 4096), (32768, 4096)),
        "group_size": 128,
        "target_max_error": 64.0,
        "target_mean_error": 6.9,
    },
    {
        "shape": ((512, 11008), (4096, 11008)),
        "group_size": 128,
        "target_max_error": 96.0,
        "target_mean_error": 11.9,
    },
    {
        "shape": ((512, 4096), (4096, 4096)),
        "group_size": 128,
        "target_max_error": 48.0,
        "target_mean_error": 6.8,
    },
    {
        "shape": ((512, 4096), (11008, 4096)),
        "group_size": 128,
        "target_max_error": 48.0,
        "target_mean_error": 6.8,
    },
    {
        "shape": ((512, 4096), (12288, 4096)),
        "group_size": 128,
        "target_max_error": 48.0,
        "target_mean_error": 6.8,
    },
    {
        "shape": ((512, 4096), (32768, 4096)),
        "group_size": 128,
        "target_max_error": 64.0,
        "target_mean_error": 6.9,
    },
    {
        "shape": ((800, 11008), (4096, 11008)),
        "group_size": 128,
        "target_max_error": 96.0,
        "target_mean_error": 11.9,
    },
    {
        "shape": ((800, 4096), (4096, 4096)),
        "group_size": 128,
        "target_max_error": 48.0,
        "target_mean_error": 6.8,
    },
    {
        "shape": ((800, 4096), (11008, 4096)),
        "group_size": 128,
        "target_max_error": 48.0,
        "target_mean_error": 6.8,
    },
    {
        "shape": ((800, 4096), (12288, 4096)),
        "group_size": 128,
        "target_max_error": 48.0,
        "target_mean_error": 6.8,
    },
    {
        "shape": ((800, 4096), (32768, 4096)),
        "group_size": 128,
        "target_max_error": 48.0,
        "target_mean_error": 6.9,
    },
    {
        "shape": ((1024, 11008), (4096, 11008)),
        "group_size": 128,
        "target_max_error": 96.0,
        "target_mean_error": 11.9,
    },
    {
        "shape": ((1024, 4096), (4096, 4096)),
        "group_size": 128,
        "target_max_error": 64.0,
        "target_mean_error": 6.8,
    },
    {
        "shape": ((1024, 4096), (11008, 4096)),
        "group_size": 128,
        "target_max_error": 64.0,
        "target_mean_error": 6.8,
    },
    {
        "shape": ((1024, 4096), (12288, 4096)),
        "group_size": 128,
        "target_max_error": 64.0,
        "target_mean_error": 6.8,
    },
    {
        "shape": ((1024, 4096), (32768, 4096)),
        "group_size": 128,
        "target_max_error": 64.0,
        "target_mean_error": 6.9,
    },
    {
        "shape": ((2048, 11008), (4096, 11008)),
        "group_size": 128,
        "target_max_error": 96.0,
        "target_mean_error": 11.9,
    },
    {
        "shape": ((2048, 4096), (4096, 4096)),
        "group_size": 128,
        "target_max_error": 64.0,
        "target_mean_error": 6.8,
    },
    {
        "shape": ((2048, 4096), (11008, 4096)),
        "group_size": 128,
        "target_max_error": 64.0,
        "target_mean_error": 6.8,
    },
    {
        "shape": ((2048, 4096), (12288, 4096)),
        "group_size": 128,
        "target_max_error": 64.0,
        "target_mean_error": 6.8,
    },
    {
        "shape": ((2048, 4096), (32768, 4096)),
        "group_size": 128,
        "target_max_error": 64.0,
        "target_mean_error": 6.9,
    },
]


other_shapes_mladf = [
    {
        "shape": ((1, 4096), (4096, 4096)),
        "group_size": 128,
        "target_max_error": 32.0,
        "target_mean_error": 6.8,
    },
    {
        "shape": ((199, 11008), (4096, 11008)),
        "group_size": 128,
        "target_max_error": 8272.0,
        "target_mean_error": 520.2,
    },
    {
        "shape": ((37, 4096), (4096, 4096)),
        "group_size": 128,
        "target_max_error": 96.0,
        "target_mean_error": 12.2,
    },
]


@pytest.mark.parametrize("xyshape", llama2_7b_mladf + other_shapes_mladf)
def test_QLinear_pergrp_mladf(xyshape, w_bit):
    inp_shape, weight_shape = xyshape["shape"]
    grpsize = xyshape["group_size"]

    if not os.getenv("MLADF"):
        pytest.skip("Test only relevant for MLADF transaction binaries.")
    elif os.getenv("MLADF") == "4x4":
        if (grpsize == 32 and weight_shape[0] != 32768) or (
            grpsize == 128 and weight_shape[0] == 32768
        ):
            pytest.skip("For 4x4 there is no full coverage with transaction binaries.")

    torch.random.manual_seed(123)
    np.random.seed(123)

    x_min, x_max = -42.0, 42.0
    x = np.random.uniform(low=x_min, high=x_max, size=inp_shape)
    x = torch.tensor(x).to(torch.bfloat16)

    y_min, y_max = -1.0, 1.0
    y = np.random.uniform(low=y_min, high=y_max, size=weight_shape).astype(np.float32)

    bias = torch.rand(y.shape[0], dtype=torch.float32)

    gemm_cpu = qlinear.QLinearPerGrp(
        in_features=inp_shape[1],
        out_features=weight_shape[0],
        bias=True,
        device="cpu",
        w_bit=w_bit,
        group_size=grpsize,
    )
    gemm_aie = qlinear.QLinearPerGrp(
        in_features=inp_shape[1],
        out_features=weight_shape[0],
        bias=True,
        device="cpu",
        w_bit=w_bit,
        group_size=grpsize,
    )

    gemm_cpu.weight = torch.from_numpy(y)
    gemm_cpu.bias = bias
    gemm_cpu.quantize_weights()
    gemm_cpu.initialize_parameters()

    gemm_aie.weight = torch.from_numpy(y)
    gemm_aie.bias = bias
    gemm_aie.quantize_weights()
    gemm_aie.device = "aie"
    gemm_aie.initialize_parameters()

    res0 = gemm_cpu(x).to(torch.float64)
    res2 = gemm_aie(x).to(torch.float64)

    print(res0)
    print(res2)

    target_max_error = xyshape["target_max_error"]
    target_mean_error = xyshape["target_mean_error"]

    err_max = (res0 - res2).abs().max()
    err_mean = (res0 - res2).abs().mean()
    print(f"max error: {err_max}, target {target_max_error}")
    print(f"mean error: {err_mean}, target {target_mean_error}")

    if (err_max <= target_max_error) and (err_mean <= target_mean_error):
        print(f"***** PASS: res0 vs res2")
        result3 = True
    else:
        print(
            f"***** FAIL: res0 vs res2: target max error {target_max_error}, target mean error {target_mean_error}"
        )
        result3 = False

    assert result3 == True
