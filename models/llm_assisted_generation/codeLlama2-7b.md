# Assisted generation - CodeLlama-7B

1, 2, 3 are demo examples

# HPT

## Target: AIE/w6a16

Speed up is more than 2.5 - 3.5x as **highlighted** below. Using **draft precision w8a8** improves performance further.

```python assisted_generation.py --model_name CodeLlama-7b-hf --task decode ```

|   Example# |   Prompt Length (tokens) |   New Tokens Generated |   Total Time (s) |   Prefill Phase (ms) |   Time/Token (ms) |   Tokens/Sec |
|------------|--------------------------|------------------------|------------------|----------------------|-------------------|--------------|
|          1 |                       69 |                    200 |          38.7009 |              1929.13 |           182.429 |      5.48159 |
|          2 |                       95 |                    200 |          39.5077 |              2489.53 |           183.868 |      5.43868 |
|          3 |                       89 |                    200 |          39.2987 |              2362.73 |           183.219 |      5.45796 |
|          4 |                      102 |                    200 |          39.6743 |              2617.36 |           184.045 |      5.43344 |
|          5 |                       67 |                    200 |          38.4311 |              1819.6  |           181.94  |      5.49631 |
|          6 |                       89 |                    200 |          39.2162 |              2412.28 |           182.848 |      5.46903 |
|          7 |                      101 |                    200 |          39.5635 |              2608.65 |           183.643 |      5.44534 |
|          8 |                      160 |                    200 |          41.9705 |              4143.18 |           187.89  |      5.32228 |
|          9 |                       74 |                    200 |          39.0861 |              2325.04 |           182.547 |      5.47803 |
|         10 |                      102 |                    200 |          39.5888 |              2616.65 |           183.629 |      5.44576 |
|         11 |                       96 |                    200 |          39.3429 |              2444.62 |           183.283 |      5.45603 |
|         12 |                       86 |                    200 |          39.0638 |              2354.75 |           182.394 |      5.48263 |
|         13 |                       92 |                    200 |          39.1986 |              2371.59 |           182.95  |      5.46596 |

```python assisted_generation.py --model_name CodeLlama-7b-hf --task decode --assisted_generation```

|   Example# |   Prompt Length (tokens) |   New Tokens Generated |   Total Time (s) |   Prefill Phase (ms) |   Time/Token (ms) |   Tokens/Sec |
|------------|--------------------------|------------------------|------------------|----------------------|-------------------|--------------|
|          1 |                       69 |                    200 |          21.9667 |              2385.4  |           65.6658 |      **15.2286** |
|          2 |                       95 |                    200 |          17.7175 |              2704.73 |           49.9166 |      **20.0334** |
|          3 |                       89 |                    200 |          28.0631 |              2417.27 |           86.2733 |      **11.5911** |
|          4 |                      102 |                    200 |          18.1075 |              3128.74 |           49.6911 |      20.1243 |
|          5 |                       67 |                    200 |          19.3823 |              2316.44 |           57.5376 |      17.38   |
|          6 |                       89 |                    200 |          17.3157 |              2385.08 |           49.6472 |      20.1421 |
|          7 |                      101 |                    200 |          18.1603 |              3130.38 |           49.9175 |      20.033  |
|          8 |                      160 |                    200 |          21.3895 |              4379.5  |           55.3193 |      18.0769 |
|          9 |                       74 |                    200 |          23.7192 |              2331.93 |           71.9385 |      13.9008 |
|         10 |                      102 |                    200 |          21.3256 |              3123.61 |           61.0575 |      16.378  |
|         11 |                       96 |                    200 |          19.3391 |              2628.79 |           55.8324 |      17.9108 |
|         12 |                       86 |                    200 |          24.0159 |              2377.99 |           72.2111 |      13.8483 |
|         13 |                       92 |                    200 |          22.799  |              2635.12 |           67.2357 |      14.8731 |


```python assisted_generation.py --model_name CodeLlama-7b-hf --task decode --assisted_generation --draft_precision w8af32```

|   Example# |   Prompt Length (tokens) |   New Tokens Generated |   Total Time (s) |   Prefill Phase (ms) |   Time/Token (ms) |   Tokens/Sec |
|------------|--------------------------|------------------------|------------------|----------------------|-------------------|--------------|
|          1 |                       69 |                    200 |          21.5156 |              2382.12 |           66.1794 |      **15.1104** |
|          2 |                       95 |                    200 |          17.1796 |              2700.71 |           49.7979 |      **20.0812** |
|          3 |                       89 |                    200 |          22.7942 |              2391.31 |           70.3864 |      **14.2073** |
|          4 |                      102 |                    200 |          17.2524 |              3106.24 |           48.3638 |      20.6766 |
|          5 |                       67 |                    200 |          21.2867 |              2329.91 |           65.2605 |      15.3232 |
|          6 |                       89 |                    200 |          17.2968 |              2375.91 |           51.2503 |      19.5121 |
|          7 |                      101 |                    200 |          16.7663 |              3099.43 |           46.5153 |      21.4983 |
|          8 |                      160 |                    200 |          23.5203 |              4371.77 |           65.158  |      15.3473 |
|          9 |                       74 |                    200 |          22.3033 |              2322.43 |           68.5092 |      14.5966 |
|         10 |                      102 |                    200 |          19.0909 |              3101.56 |           54.6168 |      18.3094 |
|         11 |                       96 |                    200 |          18.5153 |              2613.66 |           54.4621 |      18.3614 |
|         12 |                       86 |                    200 |          18.408  |              2369.35 |           54.6153 |      18.3099 |
|         13 |                       92 |                    200 |          23.7246 |              2619.15 |           72.1387 |      13.8622 |


# PHX

## Target: AIE/w6a16

Speed up is more than 2.5-3.5x as **highlighted** below. Using **draft precision w8a8** improves performance further.


```python assisted_generation.py --model_name CodeLlama-7b-hf --task decode ```

|   Example# |   Prompt Length (tokens) |   New Tokens Generated |   Total Time (s) |   Prefill Phase (ms) |   Time/Token (ms) |   Tokens/Sec |
|------------|--------------------------|------------------------|------------------|----------------------|-------------------|--------------|
|          1 |                       69 |                    200 |          57.7278 |              2873.26 |           273.473 |      3.65667 |
|          2 |                       95 |                    200 |          58.6581 |              3670.52 |           274.164 |      3.64745 |
|          3 |                       89 |                    200 |          58.3903 |              3562.48 |           273.244 |      3.65973 |
|          4 |                      102 |                    200 |          59.1826 |              3959.28 |           275.474 |      3.6301  |
|          5 |                       67 |                    200 |          57.3344 |              2740.86 |           272.365 |      3.67154 |
|          6 |                       89 |                    200 |          58.4884 |              3580.62 |           273.899 |      3.65098 |
|          7 |                      101 |                    200 |          59.1899 |              3970.33 |           275.469 |      3.63018 |
|          8 |                      160 |                    200 |          62.4278 |              6190.9  |           280.59  |      3.56392 |
|          9 |                       74 |                    200 |          58.2244 |              3520.22 |           272.899 |      3.66435 |
|         10 |                      102 |                    200 |          59.5087 |              3980.95 |           276.929 |      3.61104 |
|         11 |                       96 |                    200 |          58.9279 |              3617.19 |           275.839 |      3.6253  |
|         12 |                       86 |                    200 |          58.5916 |              3555.58 |           274.541 |      3.64245 |
|         13 |                       92 |                    200 |          58.5052 |              3589.09 |           273.918 |      3.65073 |

```python assisted_generation.py --model_name CodeLlama-7b-hf --task decode --assisted_generation```

|   Example# |   Prompt Length (tokens) |   New Tokens Generated |   Total Time (s) |   Prefill Phase (ms) |   Time/Token (ms) |   Tokens/Sec |
|------------|--------------------------|------------------------|------------------|----------------------|-------------------|--------------|
|          1 |                       69 |                    200 |          29.6421 |              3605.36 |           97.4243 |     **10.2644**  |
|          2 |                       95 |                    200 |          23.4463 |              4029.19 |           72.2211 |     **13.8464**  |
|          3 |                       89 |                    200 |          34.7206 |              3588.42 |          117.319  |      **8.52379** |
|          4 |                      102 |                    200 |          24.5915 |              4709.47 |           73.7518 |     13.559   |
|          5 |                       67 |                    200 |          25.729  |              3502.85 |           83.3778 |     11.9936  |
|          6 |                       89 |                    200 |          22.8585 |              3607.87 |           71.9862 |     13.8915  |
|          7 |                      101 |                    200 |          24.1213 |              4719.31 |           72.1614 |     13.8578  |
|          8 |                      160 |                    200 |          29.4539 |              6527.49 |           84.4315 |     11.8439  |
|          9 |                       74 |                    200 |          36.692  |              3542.25 |          125.125  |      7.99203 |
|         10 |                      102 |                    200 |          28.3462 |              4733.78 |           88.2631 |     11.3298  |
|         11 |                       96 |                    200 |          26.2581 |              3965.73 |           83.4848 |     11.9782  |
|         12 |                       86 |                    200 |          29.9822 |              3598.55 |           99.4949 |     10.0508  |
|         13 |                       92 |                    200 |          31.9642 |              3942.8  |          104.651  |      9.55557 |

```python assisted_generation.py --model_name CodeLlama-7b-hf --task decode --assisted_generation --draft_precision w8af32```

|   Example# |   Prompt Length (tokens) |   New Tokens Generated |   Total Time (s) |   Prefill Phase (ms) |   Time/Token (ms) |   Tokens/Sec |
|------------|--------------------------|------------------------|------------------|----------------------|-------------------|--------------|
|          1 |                       69 |                    200 |          30.3723 |              3632.76 |          100.861  |      **9.91466** |
|          2 |                       95 |                    200 |          23.2105 |              4047.61 |           72.6328 |     **13.7679**  |
|          3 |                       89 |                    200 |          30.8548 |              3610.46 |          102.876  |      **9.72042** |
|          4 |                      102 |                    200 |          23.5741 |              4719.87 |           70.4852 |     14.1874  |
|          5 |                       67 |                    200 |          27.4494 |              3538.71 |           90.0722 |     11.1022  |
|          6 |                       89 |                    200 |          24.1905 |              3598.25 |           77.1785 |     12.957   |
|          7 |                      101 |                    200 |          22.9747 |              4742.87 |           68.01   |     14.7037  |
|          8 |                      160 |                    200 |          30.2126 |              6545.96 |           89.2197 |     11.2083  |
|          9 |                       74 |                    200 |          30.0778 |              3566.05 |          100.205  |      9.97952 |
|         10 |                      102 |                    200 |          25.9382 |              4755.14 |           79.4449 |     12.5873  |
|         11 |                       96 |                    200 |          25.0104 |              3986.18 |           79.3623 |     12.6004  |
|         12 |                       86 |                    200 |          24.834  |              3604.82 |           79.8291 |     12.5268  |
|         13 |                       92 |                    200 |          32.5791 |              3963.28 |          107.621  |      9.2919  |

# STX (with MCDM)

## Target: AIE/w6a16

Speed up is more than 2.5-3.5x as **highlighted** below. Using **draft precision w8a8** improves performance further.

```python assisted_generation.py --model_name CodeLlama-7b-hf --task decode ```

|   Example# |   Prompt Length (tokens) |   New Tokens Generated |   Total Time (s) |   Prefill Phase (ms) |   Time/Token (ms) |   Tokens/Sec |
|------------|--------------------------|------------------------|------------------|----------------------|-------------------|--------------|
|          1 |                       69 |                    200 |          34.6467 |              2062.71 |           161.188 |      6.20394 |
|          2 |                       95 |                    200 |          35.74   |              2699.26 |           163.672 |      6.10978 |
|          3 |                       89 |                    200 |          35.3763 |              2549.73 |           162.186 |      6.16576 |
|          4 |                      102 |                    200 |          36.0524 |              2869.57 |           164.416 |      6.08212 |
|          5 |                       67 |                    200 |          34.2774 |              1922.44 |           160.302 |      6.23822 |
|          6 |                       89 |                    200 |          35.4296 |              2543.51 |           162.889 |      6.13917 |
|          7 |                      101 |                    200 |          36.0315 |              2870.26 |           164.348 |      6.08464 |
|          8 |                      160 |                    200 |          39.3212 |              4625.02 |           171.984 |      5.8145  |
|          9 |                       74 |                    200 |          34.6851 |              2318.31 |           160.365 |      6.23578 |
|         10 |                      102 |                    200 |          36.1201 |              2870.88 |           164.646 |      6.07365 |
|         11 |                       96 |                    200 |          35.7829 |              2643.05 |           164.166 |      6.09139 |
|         12 |                       86 |                    200 |          35.2987 |              2499.24 |           162.469 |      6.155   |
|         13 |                       92 |                    200 |          35.5243 |              2581.96 |           163.155 |      6.12914 |

```python assisted_generation.py --model_name CodeLlama-7b-hf --task decode --assisted_generation```

|   Example# |   Prompt Length (tokens) |   New Tokens Generated |   Total Time (s) |   Prefill Phase (ms) |   Time/Token (ms) |   Tokens/Sec |
|------------|--------------------------|------------------------|------------------|----------------------|-------------------|--------------|
|          1 |                       69 |                    200 |          28.7338 |              2493.21 |           60.6593 |      **16.4855** |
|          2 |                       95 |                    200 |          23.0756 |              2932.53 |           45.4508 |      **22.0018** |
|          3 |                       89 |                    200 |          34.2195 |              2635    |           73.3961 |      **13.6247** |
|          4 |                      102 |                    200 |          24.0174 |              3248.06 |           46.8861 |      21.3283 |
|          5 |                       67 |                    200 |          24.4791 |              2318.4  |           51.6766 |      19.3511 |
|          6 |                       89 |                    200 |          22.5736 |              2624.14 |           45.4146 |      22.0194 |
|          7 |                      101 |                    200 |          23.5972 |              3232.69 |           45.6823 |      21.8903 |
|          8 |                      160 |                    200 |          30.1753 |              4825.8  |           55.1391 |      18.1359 |
|          9 |                       74 |                    200 |          36.113  |              2424.36 |           78.228  |      12.7832 |
|         10 |                      102 |                    200 |          27.5492 |              3239.74 |           55.5354 |      18.0065 |
|         11 |                       96 |                    200 |          25.8183 |              2873.77 |           52.3701 |      19.0949 |
|         12 |                       86 |                    200 |          29.4179 |              2595.03 |           62.1173 |      16.0986 |
|         13 |                       92 |                    200 |          31.7479 |              2823.16 |           65.8298 |      15.1907 |

```python assisted_generation.py --model_name CodeLlama-7b-hf --task decode --assisted_generation --draft_precision w8af32```

|   Example# |   Prompt Length (tokens) |   New Tokens Generated |   Total Time (s) |   Prefill Phase (ms) |   Time/Token (ms) |   Tokens/Sec |
|------------|--------------------------|------------------------|------------------|----------------------|-------------------|--------------|
|          1 |                       69 |                    200 |          21.8848 |              2442.59 |           60.9701 |      **16.4015** |
|          2 |                       95 |                    200 |          16.4379 |              2916.15 |           42.2423 |      **23.673**  |
|          3 |                       89 |                    200 |          21.9727 |              2443.25 |           61.4101 |      **16.284**  |
|          4 |                      102 |                    200 |          17.2708 |              3374.65 |           43.3504 |      23.0678 |
|          5 |                       67 |                    200 |          18.6863 |              2293.03 |           51.84   |      19.2901 |
|          6 |                       89 |                    200 |          17.2968 |              2606.95 |           46.5054 |      21.5029 |
|          7 |                      101 |                    200 |          16.5785 |              3199    |           41.9618 |      23.8312 |
|          8 |                      160 |                    200 |          24.1177 |              4633.67 |           61.2489 |      16.3268 |
|          9 |                       74 |                    200 |          21.2681 |              2360.06 |           59.7009 |      16.7502 |
|         10 |                      102 |                    200 |          17.9152 |              3044.78 |           46.7602 |      21.3857 |
|         11 |                       96 |                    200 |          18.3687 |              2965    |           48.25   |      20.7254 |
|         12 |                       86 |                    200 |          18.9988 |              2247.77 |           52.7012 |      18.9749 |
|         13 |                       92 |                    200 |          20.432  |              2449.94 |           56.2636 |      17.7735 |

## PHX - Just for reference - Target: CPU/bf16   Assistant: CPU/bf16

Good examples: 4, 5, 6

| Example # | Speed-up with avg token-time       |
|-----------|------------------------------------|
| 4         | (127.24/200) / (19.17/200) = 6.64x |
| 5         | (113.28/200) / (26.91/200) = 4.21x |
| 6         | (114.32/200) / (29.09/200) = 3.93x |

```python assisted_generation.py --model_name CodeLlama-7b-hf --task decode ```
|   Example# |   Prompt Length (tokens) |   New Tokens Generated |   Total Time (s) | Prefill Phase (ms)   | Time/Token (ms)   | Tokens/Sec   |
|------------|--------------------------|------------------------|------------------|----------------------|-------------------|--------------|
|          1 |                       46 |                    200 |          76.5971 | na                   | na                | na           |
|          2 |                       59 |                    101 |          51.0573 | na                   | na                | na           |
|          3 |                       60 |                    200 |         122.628  | na                   | na                | na           |
|          4 |                        8 |                    200 |         127.239  | na                   | na                | na           |
|          5 |                       11 |                    200 |         113.278  | na                   | na                | na           |
|          6 |                       19 |                    200 |         114.322  | na                   | na                | na           |


```python assisted_generation.py --model_name CodeLlama-7b-hf --task decode --assisted_generation```
|   Example# |   Prompt Length (tokens) |   New Tokens Generated |   Total Time (s) | Prefill Phase (ms)   | Time/Token (ms)   | Tokens/Sec   |
|------------|--------------------------|------------------------|------------------|----------------------|-------------------|--------------|
|          1 |                       46 |                    200 |          12.1808 | na                   | na                | na           |
|          2 |                       59 |                    200 |          61.1979 | na                   | na                | na           |
|          3 |                       60 |                    200 |          56.8215 | na                   | na                | na           |
|          4 |                        8 |                    200 |          19.1701 | na                   | na                | na           |
|          5 |                       11 |                    200 |          26.9071 | na                   | na                | na           |
|          6 |                       19 |                    200 |          29.0898 | na                   | na                | na           |


# Human Eval (optional)
```
git clone https://gitenterprise.xilinx.com/zepingl/human-eval.git
pip install -e ./human-eval

python assisted_generation.py --model_name CodeLlama-7b-hf --task benchmark_code --assisted_generation

```
